{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fifth Step: Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import mkdir, remove\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from configurations import cfg\n",
    "from utilizations import split_data\n",
    "from capsNet import CapsNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Saving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    '''\n",
    "    <ARGUMENTS>\n",
    "        # NONE\n",
    "        \n",
    "    <OUTPUT>\n",
    "        # Training Data\n",
    "          ==> loss_results, train_accuracy_results, valid_accuracy_results\n",
    "          \n",
    "        # Testing Data\n",
    "          ==> test_accuracy_results \n",
    "          \n",
    "    [Save Files - Training]\n",
    "     - Loss, Accuracies\n",
    "     1. If there's no result directory, then make it!\n",
    "     2. If it is training_set, make csv files of loss and accuracies.\n",
    "     3. If there's past results, delete it. \n",
    "     4. Write down the loss and accuracies header on csv files that made it before.\n",
    "    '''\n",
    "\n",
    "    # 1 \n",
    "    if not exists(cfg.results):\n",
    "        mkdir(cfg.results)\n",
    "\n",
    "    # 2 ( When Training )\n",
    "    if cfg.is_training:\n",
    "        loss = cfg.results + '/loss.csv'\n",
    "        train_accuracy = cfg.results + '/train_accuracy.csv'\n",
    "        valid_accuracy = cfg.results + '/valid_accuracy.csv'\n",
    "\n",
    "    # 3     \n",
    "        if exists(loss):\n",
    "            remove(loss)\n",
    "            \n",
    "        if exists(train_accuracy):\n",
    "            remove(train_accuracy)    \n",
    "        \n",
    "        if exists(valid_accuracy):\n",
    "            remove(valid_accuracy)\n",
    "            \n",
    "    # 4\n",
    "        loss_results = open(loss, 'w')\n",
    "        loss_results.write('step,Loss\\n')\n",
    "        \n",
    "        train_accuracy_results = open(train_accuracy, 'w')\n",
    "        train_accuracy_results.write('step,Train_Accuracy\\n')\n",
    "        \n",
    "        valid_accuracy_results = open(valid_accuracy, 'w')\n",
    "        valid_accuracy_results.write('step,Valid_Accuracy\\n')\n",
    "        \n",
    "        return loss_results, train_accuracy_results, valid_accuracy_results\n",
    "    \n",
    "    else: # ( When Testing )\n",
    "        '''\n",
    "        [Save Files - Testing]\n",
    "         - Loss, Accuracies\n",
    "         1. If it is testing_set, make csv files of loss and accuracies.\n",
    "         2. If there's past results, delete it. \n",
    "         3. Write down the loss and accuracies header on csv files that made it before.\n",
    "        '''\n",
    "\n",
    "        # 1\n",
    "        test_accuracy = cfg.results + '/test_accuracy.csv'\n",
    "        \n",
    "        # 2\n",
    "        if exists(test_accuracy):\n",
    "            remove(test_accuracy)\n",
    "            \n",
    "        # 3    \n",
    "        test_accuracy_results = open(test_accuracy, 'w')\n",
    "        test_accuracy_results.write('test_accuracy\\n')\n",
    "        \n",
    "        return test_accuracy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, supervisor, num_label):\n",
    "    '''\n",
    "    [ Train the model ]\n",
    "     1. split data into training dataset, validation dataset\n",
    "     2. Save results as csv files.\n",
    "     3. Assign required GPU Memory \n",
    "    '''\n",
    "    # 1\n",
    "    X_train, y_train, train_batch_num, X_valid, y_valid, valid_batch_num = split_data(cfg.batch_size, is_training=True)\n",
    "    y = y_valid[:valid_batch_num * cfg.batch_size].reshape((-1, 1))\n",
    "\n",
    "    # 2\n",
    "    loss_results, train_accuracy_results, valid_accuracy_results = save_results()\n",
    "    \n",
    "    # 3\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    '''\n",
    "    [Data Training Start]\n",
    "     1. epoch 50 times\n",
    "     2. tqdm: Instantly make your loops show a smart progress meter\n",
    "     3. Write down the training loss and accuracies on csv files that made it before.\n",
    "     4. Write down the validation loss and accuracies on csv files that made it before.\n",
    "     5. Save model_epoch_NUM_step in logdir\n",
    "    '''\n",
    "    with supervisor.managed_session(config=config) as sess:\n",
    "        \n",
    "        print(\"\\nNote: all of results will be saved to directory: \" + cfg.results)\n",
    "        \n",
    "        # 1\n",
    "        for epoch in range(cfg.epoch):\n",
    "            print('Training for epoch ' + str(epoch) + '/' + str(cfg.epoch) + ':')\n",
    "            \n",
    "            if supervisor.should_stop():\n",
    "                print('supervisor stoped!')\n",
    "                break\n",
    "            \n",
    "            # 2 \n",
    "            for step in tqdm(range(train_batch_num), total=train_batch_num, ncols=70, leave=False, unit='b'):\n",
    "                start = step * cfg.batch_size\n",
    "                end = start + cfg.batch_size\n",
    "                global_step = epoch * train_batch_num + step\n",
    "\n",
    "                # 3\n",
    "                if global_step % cfg.train_sum_freq == 0:\n",
    "                    _, loss, train_accuracy, train_summary = sess.run([model.train_operation, model.total_loss, \n",
    "                                                                       model.accuracy, model.train_summary])\n",
    "                    \n",
    "                    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "                    \n",
    "                    supervisor.summary_writer.add_summary(train_summary, global_step)\n",
    "                     \n",
    "                    loss_results.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
    "                    loss_results.flush()\n",
    "                    train_accuracy_results.write(str(global_step) + ',' + str(train_accuracy / cfg.batch_size) + \"\\n\")\n",
    "                    train_accuracy_results.flush()\n",
    "                    \n",
    "                else:\n",
    "                    sess.run(model.train_operation)\n",
    "                \n",
    "                # 4 \n",
    "                if cfg.valid_sum_freq != 0 and (global_step) % cfg.valid_sum_freq == 0:\n",
    "                    \n",
    "                    valid_accuracy = 0\n",
    "                    \n",
    "                    for i in range(valid_batch_num):\n",
    "                        start = i * cfg.batch_size\n",
    "                        end = start + cfg.batch_size\n",
    "                        accuracy = sess.run(model.accuracy, {model.X: X_valid[start:end], model.labels: y_valid[start:end]})\n",
    "                        valid_accuracy += accuracy\n",
    "                        \n",
    "                    valid_accuracy = valid_accuracy / (cfg.batch_size * valid_batch_num)\n",
    "                    valid_accuracy_results.write(str(global_step) + ',' + str(valid_accuracy) + '\\n')\n",
    "                    valid_accuracy_results.flush()\n",
    "            # 5 \n",
    "            if (epoch + 1) % cfg.save_freq == 0:\n",
    "                supervisor.saver.save(sess, cfg.logdir + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
    "        \n",
    "        loss_results.close()\n",
    "        print('Loss results has been saved to ' + cfg.results + '/loss.csv')        \n",
    "        \n",
    "        train_accuracy_results.close()\n",
    "        print('training accuracy has been saved to ' + cfg.results + '/train_accuracy.csv')        \n",
    "        \n",
    "        valid_accuracy_results.close()\n",
    "        print('Validation accuracy has been saved to ' + cfg.results + '/valid_accuracy.csv')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Evaluation = Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(model, supervisor, num_label):\n",
    "    '''\n",
    "    [ Test the model ]\n",
    "     1. split testing dataset\n",
    "     2. Save results as csv files.\n",
    "    '''    \n",
    "    # 1\n",
    "    X_test, y_test, test_batch_num = split_data(cfg.batch_size, is_training=False)\n",
    "    \n",
    "    # 2\n",
    "    test_accuracy_results = save_results()\n",
    "\n",
    "    '''\n",
    "    [Data Testing Start]\n",
    "     1. Latest Model Restore in logdir\n",
    "     2. tqdm: Instantly make your loops show a smart progress meter\n",
    "     3. Write down the testing accuracy on csv files that made it before.\n",
    "    '''\n",
    "    # 1\n",
    "    with supervisor.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(cfg.logdir))\n",
    "        tf.logging.info('Model restored!')\n",
    "        \n",
    "        test_accuracy = 0\n",
    "        \n",
    "        # 2\n",
    "        for i in tqdm(range(test_batch_num), total=test_batch_num, ncols=70, leave=False, unit='b'):\n",
    "            start = i * cfg.batch_size\n",
    "            end = start + cfg.batch_size\n",
    "            accuracy = sess.run(model.accuracy, {model.X: X_test[start:end], model.labels: y_test[start:end]})\n",
    "            test_accuracy += accuracy\n",
    "        \n",
    "        # 3\n",
    "        test_accuracy = test_accuracy / (cfg.batch_size * test_batch_num)\n",
    "        test_accuracy_results.write(str(test_accuracy))\n",
    "        test_accuracy_results.close()\n",
    "        print('Test accuracy has been saved to ' + cfg.results + '/test_accuracy.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Start Whole Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    \n",
    "    tf.logging.info(' Graph Loading... ')\n",
    "    num_label = 10\n",
    "    model = CapsNet()\n",
    "    tf.logging.info(' Graph Loaded ! ')\n",
    "\n",
    "    sv = tf.train.Supervisor(graph=model.graph, logdir=cfg.logdir, save_model_secs=0)\n",
    "\n",
    "    if cfg.is_training:\n",
    "        tf.logging.info(' Start training...')\n",
    "        train(model, sv, num_label)\n",
    "        tf.logging.info('Training done')\n",
    "        \n",
    "    else:\n",
    "        evaluation(model, sv, num_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Let's Start the Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
